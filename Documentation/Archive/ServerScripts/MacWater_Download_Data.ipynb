{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This file allows you to download all the data from an influx DB on a webserver into .csv files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "#Get URL\n",
    "baseURL = input(\"Website URL: \")\n",
    "if (URL[-1] != '/'):\n",
    "    URL += '/'\n",
    "\n",
    "#Get file path\n",
    "filePath = input(\"Relative path to where you'd like to download the data: \")\n",
    "if (filePath != '' && filePath[-1] != '/'):\n",
    "    filePath += '/'\n",
    "\n",
    "#Create folders for file path if they dont exist\n",
    "os.makedirs(filePath, exist_ok=True)\n",
    "\n",
    "#Get location information from server\n",
    "infoResponse = requests.get(url = (baseURL + 'sensor/info'))\n",
    "infoData = infoResponse.json()[\"locations\"]\n",
    "\n",
    "#Loop through each location\n",
    "for location in infoData:\n",
    "    #Create this node's .csv file\n",
    "    file = open(filePath + \"node\" + location[0] + \".csv\", \"w+\")\n",
    "    \n",
    "    #Write the node's name\n",
    "    file.write(location[1] + '\\n')\n",
    "    \n",
    "    #Get the type information for this node\n",
    "    params = {'id': location[0]}\n",
    "    types = (requests.get(url = (baseURL + 'sensor/type'), params = params)).json()[\"types\"]\n",
    "    \n",
    "    #Write the types\n",
    "    file.write(\"Time,Latitude,Longitude\")\n",
    "    for i in types:\n",
    "        file.write(',' + i)\n",
    "    file.write('\\n')\n",
    "    \n",
    "    #Get the location history for this node\n",
    "    allLocations = (requests.get(url = (baseURL + 'sensor/info'), params = params)).json()[\"locations\"]\n",
    "    \n",
    "    #If there are sensors\n",
    "    if (len(types) != 0):\n",
    "        #Get the sensor data for every sensor\n",
    "        data = []\n",
    "        for i in types:\n",
    "            params = {'id': location[0], 'type': i}\n",
    "            currData = (requests.get(url = (baseURL + 'sensor/data'), params = params)).json()[\"data\"]\n",
    "            data.append(currData)\n",
    "\n",
    "        curr = 0\n",
    "        \n",
    "        #Loop through every data point\n",
    "        #Assumes all data points have data from every sensor\n",
    "        for i in range(len(data[0])):\n",
    "            #Write the time\n",
    "            time = int(data[0][i][0]) // 1000000\n",
    "            file.write(str(time) + ', ')\n",
    "            \n",
    "            #If this data point has a location\n",
    "            if (int(allLocations[curr][0])//1000000) == time:\n",
    "                #Write the location\n",
    "                file.write(allLocations[curr][1])\n",
    "                if (curr != len(allLocations)-1):\n",
    "                    curr += 1\n",
    "            else:\n",
    "                file.write(', ')\n",
    "            \n",
    "            #Write the sensor data\n",
    "            for j in range(len(data)):\n",
    "                file.write(', ' + data[j][i][1])\n",
    "            \n",
    "            file.write('\\n')\n",
    "    \n",
    "    #If it's only location data\n",
    "    else:\n",
    "        #Write the locations\n",
    "        for i in allLocations:\n",
    "            file.write(i[0] + ', ' + i[1] + '\\n')\n",
    "    \n",
    "    file.close()\n",
    "\n",
    "print(\"All done\")\n",
    "\n",
    "#URL for current setup: https://www.cas.mcmaster.ca/ollie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
